{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trivia QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "import json\n",
    "from predictionguard import PredictionGuard\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "pg_access_token = os.getenv('PG_API_KEY')\n",
    "os.environ['PREDICTIONGUARD_API_KEY'] = pg_access_token\n",
    "client = PredictionGuard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell if the data is not already in SQuAD.csv\n",
    "# splits = {'train': 'plain_text/train-00000-of-00001.parquet', 'validation': 'plain_text/validation-00000-of-00001.parquet'}\n",
    "# df = pd.read_parquet(\"hf://datasets/rajpurkar/squad/\" + splits[\"train\"])\n",
    "# df.to_csv('SQuAD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SQuAD_space_race.csv')\n",
    "ls_questions = list(df['question'])\n",
    "ls_answers = list(df['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_model(inputs):\n",
    "    # print(inputs)\n",
    "    prompt = \"\"\"### Instruction:\n",
    "    Answer the question in one word\n",
    "\n",
    "    ### question:\n",
    "    {inputs}\n",
    "\n",
    "    ### Response:\n",
    "    \"\"\".format(inputs=inputs)\n",
    "\n",
    "    response = client.completions.create(\n",
    "        model=\"Hermes-2-Pro-Llama-3-8B\",\n",
    "        prompt=prompt\n",
    "    )\n",
    "\n",
    "    filtered_response = response['choices'][0]['text'].split('\\n')[0].strip()\n",
    "\n",
    "    filtered_response = filtered_response.split('#')[0]\n",
    "    return filtered_response\n",
    "def create_prompt_template_variations(question):\n",
    "    # Define your prompt templates\n",
    "    prompt_templates = [\n",
    "        # Basic template\n",
    "        \"\"\"### Instruction:\n",
    "        Answer the question in one word\n",
    "        ### Question:\n",
    "        {question}\n",
    "        ### Response:\"\"\",\n",
    "        \n",
    "        # More casual\n",
    "        \"\"\"Hey! Can you answer this with just one word?\n",
    "        Question: {question}\n",
    "        Answer:\"\"\",\n",
    "        \n",
    "        # More formal\n",
    "        \"\"\"You are tasked with providing a single-word response to the following query:\n",
    "        {question}\n",
    "        Response:\"\"\",\n",
    "        \n",
    "        # Minimal\n",
    "        \"\"\"{question}\n",
    "        Answer in one word:\"\"\",\n",
    "        \n",
    "        # With emphasis\n",
    "        \"\"\"### Important: Use ONLY ONE WORD to answer\n",
    "        Question: {question}\n",
    "        Answer:\"\"\",\n",
    "    ]\n",
    "    return prompt_templates\n",
    "def test_prompt_sensitivity(question, client, prompts):\n",
    "    \"\"\"Test model's responses to different prompt formulations.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for prompt in prompts[0]:\n",
    "        response = client.completions.create(\n",
    "            model=\"Hermes-2-Pro-Llama-3-8B\",\n",
    "            prompt=prompt\n",
    "        )\n",
    "        results.append(response['choices'][0]['text'].strip())\n",
    "    \n",
    "    return results\n",
    "def calculate_semantic_similarity(responses):\n",
    "    \"\"\"\n",
    "    Calculate the average pairwise semantic similarity between responses\n",
    "    \"\"\"\n",
    "    if not responses:\n",
    "        return 0.0\n",
    "    \n",
    "    # Get embeddings for all responses\n",
    "    embeddings = model.encode(responses)\n",
    "    \n",
    "    # Calculate pairwise similarities\n",
    "    similarities = cosine_similarity(embeddings)\n",
    "    \n",
    "    # Get average similarity (excluding self-similarity)\n",
    "    n = len(responses)\n",
    "    if n <= 1:\n",
    "        return 1.0\n",
    "    \n",
    "    # Calculate mean of upper triangle (excluding diagonal)\n",
    "    total_similarity = 0\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            total_similarity += similarities[i][j]\n",
    "            count += 1\n",
    "    \n",
    "    return total_similarity / count if count > 0 else 0.0\n",
    "def create_random_variations(question):\n",
    "    import random\n",
    "    import string\n",
    "    \n",
    "    variations = []\n",
    "    for i in range(3):\n",
    "        # Convert question to list of characters for easier manipulation\n",
    "        chars = list(question)\n",
    "        \n",
    "        # Randomly select 2 positions for letter replacement\n",
    "        letter_positions = random.sample([i for i, c in enumerate(chars) if c.isalpha()], 2)\n",
    "        \n",
    "        # Replace letters with random letters\n",
    "        for pos in letter_positions:\n",
    "            chars[pos] = random.choice(string.ascii_lowercase)\n",
    "        \n",
    "        # Randomly select 1 position for capitalization\n",
    "        cap_position = random.choice([i for i, c in enumerate(chars) if c.isalpha()])\n",
    "        chars[cap_position] = chars[cap_position].upper()\n",
    "        \n",
    "        # Join back into string and add to variations\n",
    "        variations.append(''.join(chars))\n",
    "    \n",
    "    return variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_random_variations():\n",
    "    full_responses = []\n",
    "    for question in ls_questions[:2]: \n",
    "        responses = []\n",
    "        main_response = get_response_from_model(question)\n",
    "        responses.append(main_response)\n",
    "        print('Question: ', question)\n",
    "        print('Main Response: ', main_response)\n",
    "        question_variations = create_random_variations(question)\n",
    "        for variation in question_variations:\n",
    "            \n",
    "            print('Variation: ', variation)\n",
    "            response = get_response_from_model(variation)\n",
    "            print('Response: ', response)\n",
    "            responses.append(response)\n",
    "        full_responses.append(responses)\n",
    "        # print('Semantic Similarity: ', calculate_semantic_similarity(responses))\n",
    "\n",
    "    return full_responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Whose technology enabled the Space Race between the Soviet Union and the united States?\n",
      "Main Response:  German\n",
      "Variation:  Whose technology enabled the Space Race bftween the Soviet Union and the tnited States?\n",
      "Response:  Germany\n",
      "Variation:  Whose technqlogy enabled the Space Race between the Soviet Uncon and the united StAtes?\n",
      "Response:  Soviet\n",
      "Variation:  Whose techNology enabved the rpace Race between the Soviet Union and the united States?\n",
      "Response:  Soviet Unions or USA both used it?\n",
      "Question:  Who was able to launch the first orbiting satellite?\n",
      "Main Response:  Russia\n",
      "Variation:  Who tas able to launch the fiRst orbiting sadellite?\n",
      "Response:  Soviet Union\n",
      "Variation:  Who was able bo lAunch ehe first orbiting satellite?\n",
      "Response:  The Soviet Union\n",
      "Variation:  Who was aBle to launch the lirst orbiting satellhte?\n",
      "Response:  Sergey Korolev \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['German', 'Germany', 'Soviet', 'Soviet Unions or USA both used it?'],\n",
       " ['Russia', 'Soviet Union', 'The Soviet Union', 'Sergey Korolev ']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_responses = test_random_variations()\n",
    "full_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pg_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
